{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib - Explore RLlib - Custom Environments and Reward Shaping\n",
    "\n",
    "© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)\n",
    "\n",
    "This lesson demonstrates how to adapt your own problem to use [Ray RLlib](http://rllib.io).\n",
    "\n",
    "We cover two important concepts: \n",
    "\n",
    "1. How to create your own _Markov Decision Process_ abstraction.\n",
    "2. How to shape the reward of your environment so make your agent more effective. \n",
    "\n",
    "----------------\n",
    "이번 장에서는 직접 만든 환경을 Ray RLlib를 이용하여 사용하는 방법에 대해서 설명하겠습니다.\n",
    "\n",
    "이번 장의 2가지 핵심 포인트는 다음과 같습니다.\n",
    "\n",
    "1. 나만의 _Markov Decision Process_ 을 만드는 방법\n",
    "2. 효과적인 agent 학습을 위해 보상(reward)시스템을 설계하는 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, os, shutil, sys\n",
    "import gym\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..') # so we can import from \"util\"\n",
    "from util.line_plots import plot_line, plot_line_with_min_max, plot_line_with_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 12:30:12,207\tINFO resource_spec.py:212 -- Starting Ray with 85.16 GiB memory available for workers and up to 40.5 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-27 12:30:12,448\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-09-27 12:30:12,656\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '203.237.46.206',\n",
       " 'raylet_ip_address': '203.237.46.206',\n",
       " 'redis_address': '203.237.46.206:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-27_12-30-12_205959_280453/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-27_12-30-12_205959_280453/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-09-27_12-30-12_205959_280453'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do when formulating an RL problem is to specify the dimensions of your observation space and action space. Abstractions for these are provided in Gym. \n",
    "\n",
    "-------------\n",
    "강화학습(RL) 문제를 정의하는데 있어서 가장 첫 번째로 해야할 일을 관측값(observation)과 행동(action)에 대한 차원을 구체화 해야합니다.\n",
    "아래의 예제들은 Gym을 이용해 작성되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Different Actions to Their Corresponding Space\n",
    "\n",
    "Let's familiarize ourselves with different Gym spaces. For example:\n",
    "\n",
    "    discrete = spaces.Discrete(10)\n",
    "    print(\"Random sample of this space: \", [discrete.sample() for i in range(4)])\n",
    "\n",
    "Use `help(gym.spaces)` or `help([specific space])` (i.e., `help(gym.spaces.Discrete)`) for more info.\n",
    "\n",
    "--------------\n",
    "Gym에 대해서 좀더 알아 보겠습니다. 예를들어,\n",
    "\n",
    "    discrete = spaces.Discrete(10)\n",
    "    print(\"Random sample of this space: \", [discrete.sample() for i in range(4)])\n",
    "    \n",
    "help함수를 이용해 좀더 구체적인 정보를 얻을 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package gym.spaces in gym:\n",
      "\n",
      "NAME\n",
      "    gym.spaces\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    box\n",
      "    dict\n",
      "    discrete\n",
      "    multi_binary\n",
      "    multi_discrete\n",
      "    space\n",
      "    tests (package)\n",
      "    tuple\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        gym.spaces.space.Space\n",
      "            gym.spaces.box.Box\n",
      "            gym.spaces.dict.Dict\n",
      "            gym.spaces.discrete.Discrete\n",
      "            gym.spaces.multi_binary.MultiBinary\n",
      "            gym.spaces.multi_discrete.MultiDiscrete\n",
      "            gym.spaces.tuple.Tuple\n",
      "    \n",
      "    class Box(gym.spaces.space.Space)\n",
      "     |  A (possibly unbounded) box in R^n. Specifically, a Box represents the\n",
      "     |  Cartesian product of n closed intervals. Each interval has the form of one\n",
      "     |  of [a, b], (-oo, b], [a, oo), or (-oo, oo).\n",
      "     |  \n",
      "     |  There are two common use cases:\n",
      "     |  \n",
      "     |  * Identical bound for each dimension::\n",
      "     |      >>> Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)\n",
      "     |      Box(3, 4)\n",
      "     |      \n",
      "     |  * Independent bound for each dimension::\n",
      "     |      >>> Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)\n",
      "     |      Box(2,)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Box\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, low, high, shape=None, dtype=<class 'numpy.float32'>)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  is_bounded(self, manner='both')\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Generates a single random sample inside of the Box. \n",
      "     |      \n",
      "     |      In creating a sample of the box, each coordinate is sampled according to\n",
      "     |      the form of the interval:\n",
      "     |      \n",
      "     |      * [a, b] : uniform distribution \n",
      "     |      * [a, oo) : shifted exponential distribution\n",
      "     |      * (-oo, b] : shifted negative exponential distribution\n",
      "     |      * (-oo, oo) : normal distribution\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Dict(gym.spaces.space.Space)\n",
      "     |  A dictionary of simpler spaces.\n",
      "     |  \n",
      "     |  Example usage:\n",
      "     |  self.observation_space = spaces.Dict({\"position\": spaces.Discrete(2), \"velocity\": spaces.Discrete(3)})\n",
      "     |  \n",
      "     |  Example usage [nested]:\n",
      "     |  self.nested_observation_space = spaces.Dict({\n",
      "     |      'sensors':  spaces.Dict({\n",
      "     |          'position': spaces.Box(low=-100, high=100, shape=(3,)),\n",
      "     |          'velocity': spaces.Box(low=-1, high=1, shape=(3,)),\n",
      "     |          'front_cam': spaces.Tuple((\n",
      "     |              spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
      "     |              spaces.Box(low=0, high=1, shape=(10, 10, 3))\n",
      "     |          )),\n",
      "     |          'rear_cam': spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
      "     |      }),\n",
      "     |      'ext_controller': spaces.MultiDiscrete((5, 2, 2)),\n",
      "     |      'inner_state':spaces.Dict({\n",
      "     |          'charge': spaces.Discrete(100),\n",
      "     |          'system_checks': spaces.MultiBinary(10),\n",
      "     |          'job_status': spaces.Dict({\n",
      "     |              'task': spaces.Discrete(5),\n",
      "     |              'progress': spaces.Box(low=0, high=100, shape=()),\n",
      "     |          })\n",
      "     |      })\n",
      "     |  })\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Dict\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, spaces=None, **spaces_kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Discrete(gym.spaces.space.Space)\n",
      "     |  A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`. \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> Discrete(2)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Discrete\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, n)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MultiBinary(gym.spaces.space.Space)\n",
      "     |  An n-dimensional binary space. \n",
      "     |  \n",
      "     |  The argument to MultiBinary defines n.\n",
      "     |  \n",
      "     |  Example Usage:\n",
      "     |  \n",
      "     |  >> self.observation_space = spaces.MultiBinary(5)\n",
      "     |  \n",
      "     |  >> self.observation_space.sample()\n",
      "     |  \n",
      "     |      array([0,1,0,1,0], dtype =int8)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiBinary\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, n)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MultiDiscrete(gym.spaces.space.Space)\n",
      "     |  - The multi-discrete action space consists of a series of discrete action spaces with different number of actions in eachs\n",
      "     |  - It is useful to represent game controllers or keyboards where each key can be represented as a discrete action space\n",
      "     |  - It is parametrized by passing an array of positive integers specifying number of actions for each discrete action space\n",
      "     |  \n",
      "     |  Note: Some environment wrappers assume a value of 0 always represents the NOOP action.\n",
      "     |  \n",
      "     |  e.g. Nintendo Game Controller\n",
      "     |  - Can be conceptualized as 3 discrete action spaces:\n",
      "     |  \n",
      "     |      1) Arrow Keys: Discrete 5  - NOOP[0], UP[1], RIGHT[2], DOWN[3], LEFT[4]  - params: min: 0, max: 4\n",
      "     |      2) Button A:   Discrete 2  - NOOP[0], Pressed[1] - params: min: 0, max: 1\n",
      "     |      3) Button B:   Discrete 2  - NOOP[0], Pressed[1] - params: min: 0, max: 1\n",
      "     |  \n",
      "     |  - Can be initialized as\n",
      "     |  \n",
      "     |      MultiDiscrete([ 5, 2, 2 ])\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiDiscrete\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, nvec)\n",
      "     |      nvec: vector of counts of each categorical variable\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Space(builtins.object)\n",
      "     |  Defines the observation and action spaces, so you can write generic\n",
      "     |  code that applies to any Env. For example, you can choose a random\n",
      "     |  action.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Tuple(gym.spaces.space.Space)\n",
      "     |  A tuple (i.e., product) of simpler spaces\n",
      "     |  \n",
      "     |  Example usage:\n",
      "     |  self.observation_space = spaces.Tuple((spaces.Discrete(2), spaces.Discrete(3)))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tuple\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |  \n",
      "     |  __init__(self, spaces)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    flatdim(space)\n",
      "    \n",
      "    flatten(space, x)\n",
      "    \n",
      "    unflatten(space, x)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Space', 'Box', 'Discrete', 'MultiDiscrete', 'MultiBinary',...\n",
      "\n",
      "FILE\n",
      "    /usr/local/python/2.7/envs/p3.6_torch/lib/python3.6/site-packages/gym/spaces/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gym.spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Discrete in module gym.spaces.discrete:\n",
      "\n",
      "class Discrete(gym.spaces.space.Space)\n",
      " |  A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`. \n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> Discrete(2)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Discrete\n",
      " |      gym.spaces.space.Space\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, n)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  contains(self, x)\n",
      " |      Return boolean specifying if x is a valid\n",
      " |      member of this space\n",
      " |  \n",
      " |  sample(self)\n",
      " |      Randomly sample an element of this space. Can be \n",
      " |      uniform or non-uniform sampling based on boundedness of space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.spaces.space.Space:\n",
      " |  \n",
      " |  __contains__(self, x)\n",
      " |  \n",
      " |  from_jsonable(self, sample_n)\n",
      " |      Convert a JSONable data type to a batch of samples from this space.\n",
      " |  \n",
      " |  seed(self, seed=None)\n",
      " |      Seed the PRNG of this space.\n",
      " |  \n",
      " |  to_jsonable(self, sample_n)\n",
      " |      Convert a batch of samples from this space to a JSONable data type.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gym.spaces.space.Space:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gym.spaces.Discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following example values in `action_space_examples` that the correspond to the declares spaces in `action_space_map`.\n",
    "____\n",
    "아래의 예제에서 `action_space_examples`는 `action_space_map`에 대응대는 값들을 나타내고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/2.7/envs/p3.6_torch/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from gym import spaces\n",
    "\n",
    "action_space_map = {\n",
    "    \"discrete_10\": spaces.Discrete(10),\n",
    "    \"box_1\": spaces.Box(0, 1, shape=(1,), dtype=np.float64),  # the dtype can be omitted.\n",
    "    \"box_3x1\": spaces.Box(-2, 2, shape=(3, 1), dtype=np.float64),\n",
    "    \"multi_discrete\": spaces.MultiDiscrete([ 5, 2, 2, 4 ])\n",
    "}\n",
    "\n",
    "action_space_examples = {\n",
    "    \"discrete_10\": 1,\n",
    "    \"box_1\": np.array([0.89089584]),\n",
    "    \"box_3x1\": np.array([[-1.2657754], [-1.6528835], [ 0.5982418]]),\n",
    "    \"multi_discrete\": np.array([0, 0, 0, 2]),\n",
    "}\n",
    "\n",
    "for space_id, state in action_space_examples.items():\n",
    "    assert action_space_map[space_id].contains(state), (f'Looks like {space_id} to {state} is matched incorrectly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a space with 10 discrete values, 0 through 9, from which we sample and then update a counts map.\n",
    "____\n",
    "여기서 0~9까지 10개의 정수로 이루워진 공간(space)에 부터 하나를 선택(sampling)하고 횟수(count)를 업데이트 하게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 19, 1: 27, 2: 13, 3: 24, 4: 15, 5: 23, 6: 22, 7: 25, 8: 17, 9: 15}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = {key:0 for key in range(10)}\n",
    "counts\n",
    "\n",
    "for i in range(200):\n",
    "    key = spaces.Discrete(10).sample()\n",
    "    counts[key] = counts[key] + 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have more than one dimension of discrete (or continuous) values.\n",
    "______\n",
    "다차원의 (혹은 연속적인 공간에서의) 값을 설정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4, 0, 1, 0]),\n",
       " array([1, 0, 1, 2]),\n",
       " array([3, 0, 1, 3]),\n",
       " array([3, 0, 0, 0]),\n",
       " array([2, 1, 1, 0]),\n",
       " array([1, 1, 1, 2]),\n",
       " array([2, 1, 1, 1]),\n",
       " array([1, 0, 1, 0]),\n",
       " array([2, 1, 0, 0]),\n",
       " array([4, 0, 1, 1]),\n",
       " array([3, 1, 1, 2]),\n",
       " array([1, 0, 0, 0]),\n",
       " array([3, 1, 0, 1]),\n",
       " array([0, 0, 0, 3]),\n",
       " array([0, 1, 1, 3]),\n",
       " array([2, 1, 1, 2]),\n",
       " array([2, 1, 1, 0]),\n",
       " array([2, 1, 0, 0]),\n",
       " array([2, 1, 0, 3]),\n",
       " array([3, 0, 0, 3])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = spaces.MultiDiscrete([ 5, 2, 2, 4 ])\n",
    "[md.sample() for _ in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values for each dimension in the discrete space are inclusive, but zero-offset. For example, in the samples shown, the first integer returned in the array is 0-4, inclusive.\n",
    "______\n",
    "각 차원에 대한 값들은 반복적으로 선택될 수 있으며, 서로 독립적인다. 예를들어, 첫 번째 차원에서 0~4 숫자중 한가지를 독립적으로 반복하여 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.79400374, -0.89244377],\n",
       "        [ 0.65044125, -1.92038612],\n",
       "        [ 0.73991394, -1.60240738]]),\n",
       " array([[-0.89296331, -0.96551173],\n",
       "        [ 0.55588666, -0.83695289],\n",
       "        [-1.19497815,  0.36724385]]),\n",
       " array([[-1.19887293,  1.75579537],\n",
       "        [-1.77803333, -1.87905783],\n",
       "        [-0.32348429, -1.93672769]]),\n",
       " array([[ 1.9031015 ,  0.19564132],\n",
       "        [-1.55658858, -0.91911957],\n",
       "        [-1.16232201, -0.84083103]]),\n",
       " array([[ 0.87684356,  1.70554173],\n",
       "        [ 1.34991938,  0.16133106],\n",
       "        [-0.14777836, -0.76922947]]),\n",
       " array([[0.54981688, 1.67526495],\n",
       "        [0.630599  , 0.56716344],\n",
       "        [0.9435345 , 0.79983371]]),\n",
       " array([[-0.3118908 , -0.50034357],\n",
       "        [-1.29654765, -1.0501355 ],\n",
       "        [-0.32083383,  1.69562941]]),\n",
       " array([[-1.1776331 ,  0.83123156],\n",
       "        [ 1.75838583,  0.3906876 ],\n",
       "        [-0.36098672,  1.79583711]]),\n",
       " array([[ 0.9835056 , -1.55206052],\n",
       "        [-0.24646835, -0.96972703],\n",
       "        [-0.77998458, -0.58894662]]),\n",
       " array([[ 0.68186415,  0.42219094],\n",
       "        [ 1.15323613,  1.65422237],\n",
       "        [-0.57760411, -1.23515767]]),\n",
       " array([[ 1.60959035, -1.19922863],\n",
       "        [ 0.19174906,  0.23301015],\n",
       "        [-1.63559963,  0.55415467]]),\n",
       " array([[ 1.90045376,  0.30133332],\n",
       "        [ 1.35340257, -1.95369772],\n",
       "        [ 0.45525904, -1.24460789]]),\n",
       " array([[ 0.34076035, -1.08301752],\n",
       "        [-1.88298047, -0.30890182],\n",
       "        [ 1.89334021, -1.0338916 ]]),\n",
       " array([[ 1.83927731, -0.94601922],\n",
       "        [ 1.37965824,  1.32527026],\n",
       "        [-0.49856748, -1.2694119 ]]),\n",
       " array([[ 0.08394421, -0.35199769],\n",
       "        [ 1.33104554, -1.36509573],\n",
       "        [ 1.15676073,  1.98838911]]),\n",
       " array([[ 1.52126471, -0.31831248],\n",
       "        [-1.13116828, -1.57946691],\n",
       "        [ 0.76784851, -1.7723987 ]]),\n",
       " array([[ 1.12047003,  1.22685681],\n",
       "        [-1.48617181, -0.62890162],\n",
       "        [-0.30116825, -0.23321803]]),\n",
       " array([[-1.76026795, -1.87137041],\n",
       "        [ 1.02983931,  0.19713905],\n",
       "        [ 1.11248829, -1.59180522]]),\n",
       " array([[ 0.06030992,  1.4912915 ],\n",
       "        [-1.99694571,  1.99391518],\n",
       "        [ 0.90834399,  1.70083733]]),\n",
       " array([[ 1.46127832,  1.1241125 ],\n",
       "        [-0.96972968, -0.41019377],\n",
       "        [ 0.86095739, -1.18104334]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = spaces.Box(-2, 2, shape=(3,2), dtype=np.float64)\n",
    "[box.sample() for _ in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: A Custom Environment with Rewards\n",
    "\n",
    "Now we'll create an `n-Chain` environment, which represents moves along a linear chain of states, with two actions:\n",
    "\n",
    "* (0) **forward**: move along the chain but returns no reward\n",
    "* (1) **backward**: returns to the beginning and has a small reward\n",
    "\n",
    "The end of the chain, however, provides a large reward, and by moving **forward** at the end of the chain, this large reward can be repeated.\n",
    "\n",
    "_______\n",
    "이제, `n-Chain`이라는 환경을 만들어 보겠습니다. 이 환경은 선형적으로 엮여 있는 state들에 대해서 2가지의 행동(action)을 고려합니다.\n",
    "\n",
    "* (0) **forward**: 보상 없이 앞으로 이동\n",
    "* (1) **backward**: 작은 보상과 함께 처음지점으로 이동\n",
    "\n",
    "#### Step 1: Implement `ChainEnv._setup_spaces`\n",
    "\n",
    "Use a `spaces.Discrete` action space and observation space. Implement `ChainEnv._setup_spaces` in `ChainEnv` so that `self.action_space` and `self.obseration_space` are proper gym spaces.\n",
    "  \n",
    "1. The observation space is an integer in the range `[0 to n-1]`.\n",
    "2. The action space is an integer in `[0, 1]`.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "self.action_space = spaces.Discrete(2)\n",
    "self.observation_space = ...\n",
    "```\n",
    "\n",
    "You should see a message indicating tests passing when done correctly!\n",
    "\n",
    "______\n",
    "`spaces.Discrete`를 이용하여 행동(action)과 관찰(observation) 공간(space)를 만들겠습니다. 각 공간은 `self.action_space`와 `self.observation_space`로서, `ChainEnv`의 `ChainEnv._setup_spaces`에 정의됩니다.\n",
    "\n",
    "1. 관찰(observation) 공간은 `[0 to n-1]`사이의 정수를 가집니다.\n",
    "2. 행동(action) 공간은 `[0, 1]` 사이의 정수를 가집니다.\n",
    "\n",
    "예를들면 아래와 같습니다:\n",
    "\n",
    "```python\n",
    "self.action_space = spaces.Discrete(2)\n",
    "self.observation_space = ...\n",
    "```\n",
    "\n",
    "#### Step 2: Implement a reward function.\n",
    "\n",
    "When `env.step` is called, it returns a tuple of `(state, reward, done, info)`. Right now, the reward is always 0. Modify `step()` so that the following rewards are returned for the given actions: \n",
    "\n",
    "1. `action == 1` will return `self.small_reward`.\n",
    "2. `action == 0` will return 0 if `self.state < self.n - 1`.\n",
    "3. `action == 0` will return `self.large_reward` if `self.state == self.n - 1`.\n",
    "\n",
    "You should see a message indicating tests passing when done correctly. \n",
    "\n",
    "___________\n",
    "`env.step`를 호출하면, 튜플형태로 `(state, reward, done, info)`가 결과물로 나옵니다. 현재, 보상은 항상 0 입니다. `step()`을 아래같이 수행되도록 보상시스템을 수정해보세요.\n",
    "\n",
    "1. `행동(action) 이 1`일때는 `self.small_reward`을.\n",
    "2. `행동(action) 이 0`일때 만약 `self.state < self.n - 1`이라면 0을.\n",
    "3. `행동(action) 이 0`이면서 `self.state == self.n - 1`이라면, `self.large_reward`을 가집니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_exercises import test_chain_env_spaces, test_chain_env_reward, test_chain_env_behavior\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if spaces have been setup correctly...\n",
      "Success! You've setup the spaces correctly.\n",
      "Testing if reward has been setup correctly...\n",
      "Success! You've setup the rewards correctly.\n"
     ]
    }
   ],
   "source": [
    "class ChainEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, env_config = None):\n",
    "        env_config = env_config or {}\n",
    "        self.n = env_config.get(\"n\", 20)\n",
    "        self.small_reward = env_config.get(\"small\", 2)  # payout for 'backwards' action\n",
    "        self.large_reward = env_config.get(\"large\", 10)  # payout at end of chain for 'forwards' action\n",
    "        self.state = 0  # Start at beginning of the chain\n",
    "        self._horizon = self.n\n",
    "        self._counter = 0  # For terminating the episode\n",
    "        self._setup_spaces()\n",
    "    \n",
    "    def _setup_spaces(self):\n",
    "        ##############\n",
    "        # TODO: Implement this so that it passes tests\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Discrete(self.n)\n",
    "        ##############\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        if action == 1:  # 'backwards': go back to the beginning, get small reward\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = self.small_reward\n",
    "            ##############\n",
    "            self.state = 0\n",
    "        elif self.state < self.n - 1:  # 'forwards': go up along the chain\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = 0\n",
    "            self.state += 1\n",
    "        else:  # 'forwards': stay at the end of the chain, collect large reward\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = self.large_reward\n",
    "            ##############\n",
    "        self._counter += 1\n",
    "        done = self._counter >= self._horizon\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self._counter = 0\n",
    "        return self.state\n",
    "    \n",
    "# Tests here:\n",
    "test_chain_env_spaces(ChainEnv)\n",
    "test_chain_env_reward(ChainEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Policy on the Environment \n",
    "\n",
    "Now we'll train a policy on the environment and evaluate the policy. You'll see that despite an extremely high reward, the policy has barely explored the state space. \n",
    "\n",
    "In order to proceed, we'll import an implementation of the previous exercise, but you should actually comment-out the next cell once you complete the previous exercise!\n",
    "_____\n",
    "이제, 환경에 대한 정책(policy)를 훈련시키고 평가해 보겠습니다. 결과적으로 아무리 높은 보상을 준다할지라도, 정책(policy)이 상태(state) 공간(space)를 탐험하지는 않는 것을 확인할 수 있으실겁니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chain_env import ChainEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = DEFAULT_CONFIG.copy()\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config[\"train_batch_size\"] = 400\n",
    "trainer_config[\"sgd_minibatch_size\"] = 64\n",
    "trainer_config[\"num_sgd_iter\"] = 10\n",
    "trainer_config[\"framework\"] = 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(chainEnvClass, config = trainer_config, iterations=20):\n",
    "    trainer = PPOTrainer(config, chainEnvClass)\n",
    "    print(f'Training iterations: ', end='')\n",
    "    for i in range(iterations):\n",
    "        print('.', end='')\n",
    "        trainer.train()\n",
    "    print('')\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 12:30:18,348\tINFO trainer.py:612 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/usr/local/python/2.7/envs/p3.6_torch/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-09-27 12:30:25,343\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: .\u001b[2m\u001b[36m(pid=280841)\u001b[0m /usr/local/python/2.7/envs/p3.6_torch/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=280841)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "...................\n"
     ]
    }
   ],
   "source": [
    "trainer = do_training(ChainEnv, config=trainer_config, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative reward you received is: 40. Congratulations!\n",
      "Max state you visited is: 0. This is out of 20 states.\n"
     ]
    }
   ],
   "source": [
    "env = ChainEnv({})\n",
    "state = env.reset()\n",
    "\n",
    "done = False\n",
    "max_state = -1\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = trainer.compute_action(state)\n",
    "    state, reward, done, results = env.step(action)\n",
    "    max_state = max(max_state, state)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(f'Cumulative reward you received is: {cumulative_reward}. Congratulations!')\n",
    "print(f'Max state you visited is: {max_state}. This is out of {env.n} states.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only visited a small number of states, maybe only 1 or 2 (max == 0 or 1?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping the Reward to Encourage Desired Behavior\n",
    "\n",
    "We see that despite an extremely high reward, the policy has barely explored the state space. This is often the situation - where the reward designed to encourage a particular solution is suboptimal, and the behavior created is unintended.\n",
    "\n",
    "_____\n",
    "이전에 언급했듯이, 아무리 높은 보상을 준다할지라도, 정책(policy)이 상태(state) 공간(space)를 탐험하지는 않는 것을 확인할 수 있습니다. 이럴경우 보상시스템을 특정 방향 혹은 행동에 더 치중할 수 있도록 만들어 줄 수 있습니다.\n",
    "\n",
    "### Exercise 2: Improve the Policy\n",
    "\n",
    "Modify `ShapedChainEnvVisited.step()` in the next cell to return rewards that encourage the policy to traverse the chain (not just stick to 0). Do not change the behavior of the environment. That is, the action -> state behavior should be the same. You can change the reward to be whatever you wish. We'll test it in the next section.\n",
    "\n",
    "This implementation also adds a constructor argument `done_percentage`, which specifies what percentage of states, between `0.0` and `1.0` must be visited before `done` is reached. Play with this number when you modify the rewards to gain a sense of how long it takes to explore the action space. Note that there is a \"safety\"; it stops after `10*env.n` iterations, even if the percentage of visited states isn't reached. As the code exists in the following cell, it will always hit this safety!\n",
    "\n",
    "_____\n",
    "`ShapedChainEnvVisited.step()`을 수정하여 정책(policy)이 chain을 0에 머물게 하지 않고 가로지리는 행위에 대해서 보상을 받을 수 있도록 하겠습니다. 여기서 환경의 행동에 대한 부분은 수정하지 마세요. 행동(action) -> 상태(state)는 이전과 동일하면서, 원하는 행위에 대한 보상만 수정하겠습니다.\n",
    "\n",
    "여기서 `done_percentage`가 추가되는데, 이는 상태(state)들에 대한 퍼센트를 의미하며 `done`에 도달하기 전까지 방문비율을 `0.0` 에서 `1.0`사이의 숫자로 나타냅니다. 보상시스템을 수정했을때, `done_percentage`가 어떻게 달라지는지 잘 관찰해 보세요. 다만, `10*env.n`회 이상 진행될 경우, 방문비율에 상관없이 멈추도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if behavior has been changed...\n",
      "Success! Behavior of environment is correct.\n"
     ]
    }
   ],
   "source": [
    "class ShapedChainEnvVisited(ChainEnv):\n",
    "\n",
    "    def __init__(self, env_config = None):\n",
    "        super().__init__(env_config)\n",
    "        self.visited = set()\n",
    "        self.done_percentage = 0.5\n",
    "        self.done_n = self.done_percentage * self.n\n",
    "        \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        self.visited.add(self.state)\n",
    "        if action == 1:  # 'backwards': go back to the beginning\n",
    "            reward = self.small_reward*-0.1\n",
    "            self.state = 0\n",
    "        elif self.state < self.n - 1:  # 'forwards': go up along the chain\n",
    "            reward = 0\n",
    "            self.state += 1\n",
    "        else:  # 'forwards': stay at the end of the chain\n",
    "            reward = self.large_reward\n",
    "        self._counter += 1\n",
    "        done = len(self.visited) >= self.done_n\n",
    "        if not done and self._counter > (self.n*10):\n",
    "            done = True\n",
    "            visited_per = (len(self.visited)*100.0)/self.n\n",
    "            print(f'Stopping after {self.n*10} iterations. Visited {visited_per:6.2f}% of the states.')\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "test_chain_env_behavior(ShapedChainEnvVisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate `ShapedChainEnv` by Running the Cell(s) Below\n",
    "\n",
    "This trains PPO on the new env and counts the number of states seen.\n",
    "___\n",
    "PPO 알고리즘을 적용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-27 12:32:40,994\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: .\u001b[2m\u001b[36m(pid=280845)\u001b[0m /usr/local/python/2.7/envs/p3.6_torch/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=280845)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=280845)\u001b[0m Stopping after 200 iterations. Visited  30.00% of the states.\n",
      ".\u001b[2m\u001b[36m(pid=280845)\u001b[0m Stopping after 200 iterations. Visited  40.00% of the states.\n",
      "..................\n"
     ]
    }
   ],
   "source": [
    "trainer = do_training(ShapedChainEnvVisited, config=trainer_config, iterations=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how long it takes to get to 50% (the value hard-coded for `done_percentage`). \n",
    "___\n",
    "`done_percentage`가 50%에 도달하기까지 얼마나 걸리는지 한번 관찰해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative reward you received is: -3.0000000000000004!\n",
      "Max state you visited is: 10. (There are 20 states.)\n",
      "This policy traversed 55.0% of the available states.\n"
     ]
    }
   ],
   "source": [
    "env = ShapedChainEnvVisited({})\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "max_state = -1\n",
    "cumulative_reward = 0\n",
    "while not done:\n",
    "    action = trainer.compute_action(state)\n",
    "    state, reward, done, results = env.step(action)\n",
    "    max_state = max(max_state, state)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(f'Cumulative reward you received is: {cumulative_reward}!')\n",
    "print(f'Max state you visited is: {max_state}. (There are {env.n} states.)')\n",
    "desired = env.done_percentage\n",
    "actual = (max_state+1)/env.n  # add one because of zero indexing\n",
    "print(f\"This policy traversed {actual*100:4.1f}% of the available states.\")\n",
    "assert actual > desired, f\"{actual*100:4.1f}% is less than the desired percentage of {desired*100:4.1f}%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # \"Undo ray.init()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p3.6_torch]",
   "language": "python",
   "name": "conda-env-p3.6_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
