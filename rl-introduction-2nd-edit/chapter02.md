# Chapter 2
## Exercise
1. 입실론 탐욕적 행동 선택에서 두 개의 행동이 있고 <img src="/rl-introduction-2nd-edit/tex/4f5b0033a3e7c19b1b1e947f7f15ba5a.svg?invert_in_darkmode&sanitize=true" align=middle width=50.58777734999998pt height=21.18721440000001pt/>라면 탐욕적 행동을 선택할 확률은 얼마인가?
* 행동이 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>이 있다고 할 때,

2. **다중 선택 예제** 네 개의 행동 중 하나를 선택하는 다중 선택 문제를 생각해 보자. 각 행동은 번호 1, 2, 3, 4로 구분한다.(<img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/b3bed8ed07ed6311697ff7b39933375f.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/f87dcdc9f19dd4b14e54687dc1069783.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>) 이 문제에 입실론 탐욕적 행동 선택을 이용한 다중 선택 알고리즘을 적용한다고 생각해 보자. 이때 이 알고리즘은 표본 평균 행동 가치 추정값을 이용하고 초기 추정값 <img src="/rl-introduction-2nd-edit/tex/3fc01f9433855fb3c7801b5d10862d64.svg?invert_in_darkmode&sanitize=true" align=middle width=71.98131269999999pt height=24.65753399999998pt/>을 적용한다. 시간 단계에 따른 행동 및 가치의 몇몇 초기값들이 <img src="/rl-introduction-2nd-edit/tex/34cbf6179df2d91e4ba03c7b8682d15a.svg?invert_in_darkmode&sanitize=true" align=middle width=590.4881812499999pt height=22.465723500000017pt/>이라고 가정해보자. 이 시간 단계 중 일부에서 행동이 무작위로 선택되는 입실론 상황이 발행했을 수 있다. 어떤 시간 단계에서 이 상황이 확실하게 발생했을까? 어떤 시간 단계에서 이 상황이 발생하는 것이 가능했을까?

3. 그림 2.2의 비교 그래프에서 `누적 보상`과 `최고의 행동을 선택할 확률`을 고려할 때 어떤 방법이 장기적으로 가장 좋은 성능을 보여줄 것인가? 얼마나 더 좋을 것인가? 이 문제에 대해 정량적으로 답변해 보라.

4. 시간 간격의 크기 <img src="/rl-introduction-2nd-edit/tex/69533fe94ebdbe9cbed32f37b8365bb6.svg?invert_in_darkmode&sanitize=true" align=middle width=18.64167029999999pt height=14.15524440000002pt/>이 고정된 값이 아니라면 추정값 <img src="/rl-introduction-2nd-edit/tex/64d0afab00e7391a072599284b91840f.svg?invert_in_darkmode&sanitize=true" align=middle width=21.121448699999988pt height=22.465723500000017pt/>
은 이전까지 받은 보상들의 가중 평균이고, 이때 가중치는 식 2.6에서 주어지는 것과는 다르다. 식 2.6과 유사한 일반적인 경우에 있어서 바로 이전 보상에 적용할 가중치는 얼마인가? 시간 간격의 크기와 관련하여 답변해 보라.

5. *programming* 표본평균 방법을 비정상적(nonstationart) 문제에 적용하기 어렵다는 점을 보여주는 실험을 설계하고 수행하라. 모든 <img src="/rl-introduction-2nd-edit/tex/efc6578f07cd54c96cc674beb6d67c8a.svg?invert_in_darkmode&sanitize=true" align=middle width=36.36998804999999pt height=24.65753399999998pt/>가 동일한 초깃값으로부터 시작하며 독립적으로 무작위 값을 갖도록 변형한 10중 선택 문제를 활용하라(말하자면, 평균이 0이고 표준 편차가 0.01인 정규 분포를 따르는 확률 변수를 각 시간 단계에서 <img src="/rl-introduction-2nd-edit/tex/efc6578f07cd54c96cc674beb6d67c8a.svg?invert_in_darkmode&sanitize=true" align=middle width=36.36998804999999pt height=24.65753399999998pt/>에 더하도록 함으로써). 점증적으로 계산한 표본평균을 활용하는 행동 가치 방법과 고정된 시간 간격(<img src="/rl-introduction-2nd-edit/tex/6bc8e9f14104cfc2a848bdf86f2fca37.svg?invert_in_darkmode&sanitize=true" align=middle width=53.49877169999999pt height=21.18721440000001pt/>)을 사용하는 또 다른 행동 가치 방법에 대해 각각 그림 2.2와 같은 그래프를 그려 보라. <img src="/rl-introduction-2nd-edit/tex/946d41bc6d842a13d5592e2a97cc48fd.svg?invert_in_darkmode&sanitize=true" align=middle width=50.58777734999998pt height=21.18721440000001pt/>을 적용하고 더 많은 단계, 말하자면 10,000번의 단계를 적용해 보라.

## Q&A