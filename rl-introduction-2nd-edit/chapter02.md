# Chapter 2
## Exercise
1. 입실론 탐욕적 행동 선택에서 두 개의 행동이 있고 <img src="/rl-introduction-2nd-edit/tex/4f5b0033a3e7c19b1b1e947f7f15ba5a.svg?invert_in_darkmode&sanitize=true" align=middle width=50.58777734999998pt height=21.18721440000001pt/>라면 탐욕적 행동을 선택할 확률은 얼마인가?
> 행동이 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>이 있고, 최적 행동이 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>이라고 하자. <img src="/rl-introduction-2nd-edit/tex/4f5b0033a3e7c19b1b1e947f7f15ba5a.svg?invert_in_darkmode&sanitize=true" align=middle width=50.58777734999998pt height=21.18721440000001pt/>이기 때문에 <img src="/rl-introduction-2nd-edit/tex/3f19f7d8b2166a43a561f2a4f59dd203.svg?invert_in_darkmode&sanitize=true" align=middle width=78.89817704999999pt height=21.18721440000001pt/>이고 따라서 50% 확률로 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>을 선택하게 된다. 나머지 50% 선택은 가능한 모든 행동을 균등한 확률로(random) 두고 하게 된다. 따라서 <img src="/rl-introduction-2nd-edit/tex/56653dce53defc40d7f95771f2416fc2.svg?invert_in_darkmode&sanitize=true" align=middle width=108.67573529999999pt height=21.18721440000001pt/>, 즉 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>를 각각 25% 확률로 선택하게 된다. 정리해보면 최적 행동인 <img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>은 <img src="/rl-introduction-2nd-edit/tex/2e3765e074a4e2165a4f8c6675f1867f.svg?invert_in_darkmode&sanitize=true" align=middle width=121.46116949999997pt height=21.18721440000001pt/>, 75% 확률로 선택되며 <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>는 <img src="/rl-introduction-2nd-edit/tex/512128b1ead18bed472a510dafa27a24.svg?invert_in_darkmode&sanitize=true" align=middle width=29.22385289999999pt height=21.18721440000001pt/>, 25% 확률로 선택된다.

2. **(다중 선택 예제)** 네 개의 행동 중 하나를 선택하는 다중 선택 문제를 생각해 보자. 각 행동은 번호 1, 2, 3, 4로 구분한다.(<img src="/rl-introduction-2nd-edit/tex/079b75fd563cf05b47623e06b2003e64.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/764723ea3a0da0f66aaee1ae987f6abf.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/b3bed8ed07ed6311697ff7b39933375f.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>, <img src="/rl-introduction-2nd-edit/tex/f87dcdc9f19dd4b14e54687dc1069783.svg?invert_in_darkmode&sanitize=true" align=middle width=15.24170009999999pt height=14.15524440000002pt/>) 이 문제에 입실론 탐욕적 행동 선택을 이용한 다중 선택 알고리즘을 적용한다고 생각해 보자. 이때 이 알고리즘은 표본 평균 행동 가치 추정값을 이용하고 초기 추정값 <img src="/rl-introduction-2nd-edit/tex/3fc01f9433855fb3c7801b5d10862d64.svg?invert_in_darkmode&sanitize=true" align=middle width=71.98131269999999pt height=24.65753399999998pt/>을 적용한다. 시간 단계에 따른 행동 및 가치의 몇몇 초기값들이 <img src="/rl-introduction-2nd-edit/tex/c4627d7c3e5d42229a5167cfc99140f6.svg?invert_in_darkmode&sanitize=true" align=middle width=69.01824929999998pt height=24.65753399999998pt/>a_{1}<img src="/rl-introduction-2nd-edit/tex/212b922b9e5eb33ea1d3651eaa804068.svg?invert_in_darkmode&sanitize=true" align=middle width=152.8009395pt height=24.65753399999998pt/>a_{2}<img src="/rl-introduction-2nd-edit/tex/a3fa16508b7ac1711e0aed8dbee1f4a3.svg?invert_in_darkmode&sanitize=true" align=middle width=140.01550695pt height=24.65753399999998pt/>a_{2}<img src="/rl-introduction-2nd-edit/tex/497237e8bb25706b263a5c8a8814f7ec.svg?invert_in_darkmode&sanitize=true" align=middle width=152.8009395pt height=24.65753399999998pt/>a_{2}<img src="/rl-introduction-2nd-edit/tex/591cc6d40b3d06c69a5e29f4e2e15439.svg?invert_in_darkmode&sanitize=true" align=middle width=140.01550695pt height=24.65753399999998pt/>a_{3}<img src="/rl-introduction-2nd-edit/tex/2179ae5bb7fae231a936b172311cedfc.svg?invert_in_darkmode&sanitize=true" align=middle width=88.34900249999998pt height=78.90410880000002pt/>t_{1}<img src="/rl-introduction-2nd-edit/tex/ea34d5c51b4528119d5024e5eeff7d2d.svg?invert_in_darkmode&sanitize=true" align=middle width=4.5662248499999905pt height=24.65753399999998pt/>t_{2}<img src="/rl-introduction-2nd-edit/tex/ea34d5c51b4528119d5024e5eeff7d2d.svg?invert_in_darkmode&sanitize=true" align=middle width=4.5662248499999905pt height=24.65753399999998pt/>t_{3}<img src="/rl-introduction-2nd-edit/tex/ea34d5c51b4528119d5024e5eeff7d2d.svg?invert_in_darkmode&sanitize=true" align=middle width=4.5662248499999905pt height=24.65753399999998pt/>t_{4}<img src="/rl-introduction-2nd-edit/tex/ea34d5c51b4528119d5024e5eeff7d2d.svg?invert_in_darkmode&sanitize=true" align=middle width=4.5662248499999905pt height=24.65753399999998pt/>t_{5}<img src="/rl-introduction-2nd-edit/tex/bb6cbecff42a0da725a09a5b6c576433.svg?invert_in_darkmode&sanitize=true" align=middle width=663.01074345pt height=24.65753399999998pt/>a_{1}<img src="/rl-introduction-2nd-edit/tex/a72a64f05ca0af7e6073baeeb5953d6e.svg?invert_in_darkmode&sanitize=true" align=middle width=320.96182964999997pt height=24.65753399999998pt/>a_{2}<img src="/rl-introduction-2nd-edit/tex/2a9658e786849f12a00dd00956082ddf.svg?invert_in_darkmode&sanitize=true" align=middle width=606.722721pt height=24.65753399999998pt/>a_{3}<img src="/rl-introduction-2nd-edit/tex/8b077b89b0dd715270273657a3107988.svg?invert_in_darkmode&sanitize=true" align=middle width=220.5058746pt height=24.65753399999998pt/>a_{4}<img src="/rl-introduction-2nd-edit/tex/99c369a02e621c06fe69a3a753077614.svg?invert_in_darkmode&sanitize=true" align=middle width=265.2968769pt height=78.90410880000002pt/>\alpha_{n}<img src="/rl-introduction-2nd-edit/tex/b07d500f816e9e7e7a1b1da13a396846.svg?invert_in_darkmode&sanitize=true" align=middle width=8.21920935pt height=14.15524440000002pt/>Q_{n}<img src="/rl-introduction-2nd-edit/tex/5c8238942705a9ae538f96ccd98b6907.svg?invert_in_darkmode&sanitize=true" align=middle width=115.52524994999997pt height=24.65753399999998pt/><img src="/rl-introduction-2nd-edit/tex/f5b1fc8e37239eae023816ffbd58758e.svg?invert_in_darkmode&sanitize=true" align=middle width=353.8626531pt height=209.14988819999996pt/><img src="/rl-introduction-2nd-edit/tex/feae5cb7e8d14ecdab7f10f96ef39d65.svg?invert_in_darkmode&sanitize=true" align=middle width=313.92771630000004pt height=87.12328679999997pt/>q_{*}(a)<img src="/rl-introduction-2nd-edit/tex/be86619070206fa5ddb6cd7605dd1d7f.svg?invert_in_darkmode&sanitize=true" align=middle width=67.58008124999998pt height=24.65753399999998pt/>q_{*}(a)<img src="/rl-introduction-2nd-edit/tex/33dc7883b21a595e06304151c1378fb4.svg?invert_in_darkmode&sanitize=true" align=middle width=17.35165739999999pt height=24.65753399999998pt/>\alpha=0.1<img src="/rl-introduction-2nd-edit/tex/46c765b1ad3c686ff9bb588a7e42d1aa.svg?invert_in_darkmode&sanitize=true" align=middle width=31.96358384999999pt height=24.65753399999998pt/>\varepsilon=0.1$을 적용하고 더 많은 단계, 말하자면 10,000번의 단계를 적용해 보라.

> 

## Q&A